{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Retention Optimizer â€” End-to-End Pipeline\n",
    "\n",
    "This notebook runs the full pipeline:\n",
    "1. Download data\n",
    "2. Process & engineer features\n",
    "3. Train churn model\n",
    "4. Optimize retention offers\n",
    "5. Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure project root is on the path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.download_data import download\n",
    "\n",
    "download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process & Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process import get_spark, load_and_clean, build_features, detect_outliers, cluster_customers, save_features\n",
    "\n",
    "spark = get_spark()\n",
    "sdf = load_and_clean(spark)\n",
    "pdf = build_features(sdf)\n",
    "pdf = detect_outliers(pdf)\n",
    "pdf = cluster_customers(pdf)\n",
    "save_features(pdf)\n",
    "spark.stop()\n",
    "\n",
    "print(f\"\\nShape: {pdf.shape}\")\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Churn Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import load_data, train_model, FEATURE_COLS, PROJECT_ROOT as PR\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "mlflow.set_tracking_uri(str(PR / \"mlruns\"))\n",
    "mlflow.set_experiment(\"churn-prediction\")\n",
    "\n",
    "df, X, y = load_data()\n",
    "print(f\"Samples: {len(y):,}  |  Churn rate: {y.mean():.2%}\")\n",
    "\n",
    "best_model, metrics, y_prob, roc_data = train_model(X, y)\n",
    "\n",
    "with mlflow.start_run(run_name=\"notebook_run\"):\n",
    "    mlflow.log_metrics({k: v for k, v in metrics.items() if isinstance(v, (int, float))})\n",
    "    mlflow.sklearn.log_model(best_model, \"churn_model\")\n",
    "\n",
    "df[\"p_churn\"] = y_prob\n",
    "df.to_parquet(PR / \"data\" / \"processed\" / \"customer_features.parquet\", index=False)\n",
    "\n",
    "roc_df = pd.DataFrame({\"fpr\": roc_data[0], \"tpr\": roc_data[1]})\n",
    "roc_df.to_csv(PR / \"data\" / \"outputs\" / \"roc_data.csv\", index=False)\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimize Retention Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimize import optimize\n",
    "\n",
    "df = pd.read_parquet(PR / \"data\" / \"processed\" / \"customer_features.parquet\")\n",
    "result = optimize(df, budget=5000.0, max_large_pct=0.10)\n",
    "result.to_csv(PR / \"data\" / \"outputs\" / \"offer_plan.csv\", index=False)\n",
    "\n",
    "result[[\"CustomerID\", \"p_churn\", \"offer\", \"offer_cost\", \"expected_saved_revenue\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.report import plot_segments, plot_outliers, plot_roc, plot_offers, FIGURES_DIR\n",
    "\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_parquet(PR / \"data\" / \"processed\" / \"customer_features.parquet\")\n",
    "\n",
    "plot_segments(df, FIGURES_DIR / \"segments.png\")\n",
    "plot_outliers(df, FIGURES_DIR / \"outliers.png\")\n",
    "plot_roc(FIGURES_DIR / \"roc_curve.png\")\n",
    "plot_offers(result, FIGURES_DIR / \"offer_allocation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "for fname in [\"segments.png\", \"outliers.png\", \"roc_curve.png\", \"offer_allocation.png\"]:\n",
    "    fpath = FIGURES_DIR / fname\n",
    "    if fpath.exists():\n",
    "        print(f\"\\n--- {fname} ---\")\n",
    "        display(Image(filename=str(fpath), width=700))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
